## 概览

`Hadoop`分布式文件系统`HDFS`被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。`HDFS`是一个高度容错性的系统，适合部署在廉价的机器上。`HDFS`能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。`HDFS`放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。`HDFS`在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。

## 前提以及`HDFS`的设计目标

### 硬件故障

硬件发生故障是常态，`HDFS`可能由成百上千的服务器所构成，每个服务器上存储着文件系统的部分数据。我们面对的现实是构成系统的组件数目是巨大的，而且任一组件都有可能失效，这意味着总是有一部分HDFS的组件是不工作的。因此**错误检测和快速、自动的恢复是HDFS最核心的架构目标。**

### 流式数据访问

在`HDFS`上运行的应用程序需要对其数据集进行流式访问。它们不是通常在通用文件系统上运行的通用应用程序。`HDFS`更多的是为批处理而不是用户交互使用而设计的。重点是数据访问的高吞吐量, 而不是数据访问的低延迟。`POSIX`提供了许多针对`HDFS`的应用程序不需要的硬要求。在几个关键领域中, 提出了这样的交易, 以提高数据吞吐量。

### 大型数据集

在`HDFS`上运行的应用程序具有大型数据集。`HDFS`中的典型文件大小为GB到TB。因此, `HDFS`进行了调整, 以支持大型文件。它应提供较高的聚合数据带宽, 并扩展到单个群集中的数百个节点。它应该在一个实例中支持数千万个文件。

### 