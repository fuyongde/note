## 概览

`Hadoop`分布式文件系统`HDFS`被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。`HDFS`是一个高度容错性的系统，适合部署在廉价的机器上。`HDFS`能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。`HDFS`放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。`HDFS`在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。

## HDFS特点

- 硬件容错

硬件发生故障是常态，`HDFS`可能由成百上千的服务器所构成，每个服务器上存储着文件系统的部分数据。我们面对的现实是构成系统的组件数目是巨大的，而且任一组件都有可能失效，这意味着总是有一部分HDFS的组件是不工作的。因此**错误检测和快速、自动的恢复是HDFS最核心的架构目标。**

- 流式数据访问

在`HDFS`上运行的应用程序需要对其数据集进行流式访问。它们不是通常在通用文件系统上运行的通用应用程序。`HDFS`更多的是为批处理而不是用户交互使用而设计的。重点是数据访问的高吞吐量, 而不是数据访问的低延迟。`POSIX`提供了许多针对`HDFS`的应用程序不需要的硬要求。在几个关键领域中, 提出了这样的交易, 以提高数据吞吐量。

- 大型数据集

在`HDFS`上运行的应用程序具有大型数据集。`HDFS`中的典型文件大小为GB到TB。因此, `HDFS`进行了调整, 以支持大型文件。它应提供较高的聚合数据带宽, 并扩展到单个群集中的数百个节点。并且在单个实例中应支持数千万个文件。

- 简单的数据一致性

`HDFS`提供`一次写入多次读取`的数据存储模型。一个文件写入之后，则不能改变，但在文件结尾追加内容是允许的，这种模型简化了数据一致性的问题，使得高吞吐量的访问成为可能。

- 移动计算代替移动数据

如果应用程序在其操作的数据附近执行，则计算所请求的计算效率更高，当数据集大时更是如此。这可以最大限度地减少网络拥塞并提高系统的整体吞吐量。假设通常更好的是将计算迁移到更靠近数据所在的位置，而不是将数据移动到运行应用程序的位置。`HDFS`为应用程序提供了接口，使其自身更靠近数据所在的位置。

- 异构软硬件平台的可移植性

`HDFS`在设计的时候就考虑到平台的可移植性。这种特性方便了HDFS作为大规模数据应用平台的推广。
